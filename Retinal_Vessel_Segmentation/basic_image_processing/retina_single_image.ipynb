{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81a0f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa83a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filter(img, kernel, K):\n",
    "    dummy = np.copy(img)\n",
    "    kernel = np.pad(kernel, [(0, dummy.shape[0] - kernel.shape[0]), (0, dummy.shape[1] - kernel.shape[1])], 'constant')\n",
    "    # Fourier Transform\n",
    "    dummy = fft2(dummy)\n",
    "    kernel = fft2(kernel)\n",
    "    kernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K)\n",
    "    dummy = dummy * kernel\n",
    "    dummy = np.abs(ifft2(dummy))\n",
    "    return np.uint8(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a25b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectedComponents(thresh1):\n",
    "    ## Remove small object in vessel_01\n",
    "            #find all your connected components (white blobs in your image)\n",
    "    bin_uint8 = (thresh1 * 255).astype(np.uint8)\n",
    "    nb_components, output, stats, centroids = cv.connectedComponentsWithStats(bin_uint8, connectivity=8)\n",
    "            #connectedComponentswithStats yields every seperated component with information on each of them, such as size\n",
    "            #the following part is just taking out the background which is also considered a component, but most of the time we don't want that.\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "            # minimum size of particles we want to keep (number of pixels)\n",
    "            #here, it's a fixed value, but you can set it as you want, eg the mean of the sizes or whatever\n",
    "    min_size = 100\n",
    "            ## Vessel connected component\n",
    "    vessel_01 = np.zeros((output.shape))\n",
    "            #for every component in the image, you keep it only if it's above min_size\n",
    "    for ii in range(0, nb_components):\n",
    "        if sizes[ii] >= min_size:\n",
    "            vessel_01[output == ii + 1] = 255\n",
    "    return vessel_01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a882071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(vessel_01,mask):\n",
    "    ret,thresh1 = cv.threshold(vessel_01,150,255,cv.THRESH_BINARY)\n",
    "    thresh1=thresh1/255\n",
    "    ret1,thresh_mask = cv.threshold(mask,120,255,cv.THRESH_BINARY)\n",
    "    thresh_mask=thresh_mask/255\n",
    "    new=thresh_mask*th3\n",
    "    se = cv.getStructuringElement(cv.MORPH_ELLIPSE,(9,9))\n",
    "    maskIdx = cv.erode(thresh_mask,se,iterations = 2)\n",
    "    newImg = thresh_mask* np.uint8(maskIdx);\n",
    "    without_border=newImg*thresh1;\n",
    "    cv.imshow('img_without_border',without_border)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    return without_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6428eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_tn(img_ground_truth,wid_border):\n",
    "    idx_tp = 0\n",
    "    idx_tn = 0\n",
    "    idx_fp = 0\n",
    "    idx_fn = 0\n",
    "    img_tp=np.zeros_like(wid_border)\n",
    "    img_tn=np.zeros_like(wid_border)\n",
    "    img_fp=np.zeros_like(wid_border)\n",
    "    img_fn=np.zeros_like(wid_border)\n",
    "\n",
    "    for i in range(wid_border.shape[0]):\n",
    "        for j in range(wid_border.shape[1]):\n",
    "            if wid_border[i,j]==img_ground_truth[i,j] and wid_border[i,j]==1.0:\n",
    "                idx_tp +=1\n",
    "                img_tp[i,j]=255\n",
    "            elif wid_border[i,j]==img_ground_truth[i,j] and wid_border[i,j]==0.0:\n",
    "                idx_tn +=1\n",
    "                img_tn[i,j]=255\n",
    "            elif wid_border[i,j]!=img_ground_truth[i,j] and wid_border[i,j]==1.0:\n",
    "                idx_fp +=1\n",
    "                img_fp[i,j]=255\n",
    "            elif wid_border[i,j]!=img_ground_truth[i,j] and wid_border[i,j]==0.0:\n",
    "                idx_fn +=1\n",
    "                img_fn[i,j]=255\n",
    "    cv.imshow('img_tp',img_tp)\n",
    "    cv.imshow('img_tn',img_tn)\n",
    "    cv.imshow('img_fp',img_fp)\n",
    "    cv.imshow('img_fn',img_fn)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    print(\"True positives are\",idx_tp)\n",
    "    print(\"True negatives are\",idx_tn)\n",
    "    print(\"False positives are\",idx_fp)\n",
    "    print(\"False negatives are\",idx_fn)\n",
    "    print(\"Sensitivity is\",idx_tp/(idx_tp+idx_fn))\n",
    "    print(\"Specificity is\",idx_tn/(idx_tn+idx_fp))\n",
    "    print(\"Accuracy\",(idx_tp+idx_tn)/(idx_tp+idx_tn+idx_fp+idx_fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b752a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives are 16359\n",
      "True negatives are 248379\n",
      "False positives are 33677\n",
      "False negatives are 31545\n",
      "Sensitivity is 0.3414954909819639\n",
      "Specificity is 0.8806017244802451\n",
      "Accuracy 0.8023336161959025\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('2_training.jpg')\n",
    "mask=cv.imread('02_mask.jpg',cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "b,g,r=cv.split(img)\n",
    "\n",
    "clahe = cv.createCLAHE(clipLimit=3, tileGridSize=(8,8))\n",
    "enhanced_image = clahe.apply(g)\n",
    "\n",
    "th = cv.adaptiveThreshold(enhanced_image,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C ,cv.THRESH_BINARY,15,2);\n",
    "\n",
    "not_th=cv.bitwise_not(th)\n",
    "\n",
    "not_converted_rgb= cv.cvtColor(not_th, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "img_Lab= cv.cvtColor(not_converted_rgb, cv.COLOR_RGB2Lab)\n",
    "\n",
    "kernel = np.array([[-1,-1,-1],\n",
    "                   [-1, 10,-1],\n",
    "                   [-1,-1,-1]])\n",
    "\n",
    "L,a,b=cv.split(img_Lab)\n",
    "\n",
    "sharpened = cv.filter2D(L, -1, kernel)\n",
    "\n",
    "img_Lab[:,:,1]=sharpened\n",
    "final_sharpened= cv.cvtColor(img_Lab, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "# Perform Weiner Filtering\n",
    "w_kernel = np.array([[0.0128,0.0876,0.0128],\n",
    "                   [0.0876,0.5986,0.0876],\n",
    "                   [0.0128,0.0876,0.0128]])\n",
    "\n",
    "Weiner = wiener_filter(final_sharpened, w_kernel, 50)\n",
    "\n",
    "# Perform Otsu Thresholding\n",
    "ret3,th3 = cv.threshold(Weiner,0,255,cv.THRESH_OTSU)\n",
    "\n",
    "# Perform Morphological Opening to extract the blood vessels.\n",
    "m_kernel = np.array([[1, 1, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 1]]\n",
    "                   ,np.uint8)\n",
    "opening = cv.morphologyEx(th3, cv.MORPH_OPEN, m_kernel)\n",
    "\n",
    "opening_dilate = cv.dilate(opening,m_kernel,iterations = 1)\n",
    "\n",
    "ret,thresh1 = cv.threshold(opening_dilate,150,255,cv.THRESH_BINARY)\n",
    "thresh1=thresh1/255\n",
    "\n",
    "img_ground_truth=cv.imread('02_manual1.jpg',cv.IMREAD_GRAYSCALE)\n",
    "img_ground_truth=img_ground_truth/255\n",
    "\n",
    "connected_comp_img = connectedComponents(thresh1)\n",
    "\n",
    "masked_img = masking(connected_comp_img,mask)\n",
    "\n",
    "tp_tn(img_ground_truth, masked_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38700979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
